{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III Web Scraping\n",
    "\n",
    "<img src=\"http://hirinfotech.com/wp-content/uploads/2019/10/What-is-Web-Scraping-1024x512.png\" width=\"791\" height=\"396\">\n",
    "\n",
    "* Término usado para describir el uso de un programa o algoritmo para extraer y procesar grandes cantidades de datos de la web.\n",
    "* Hay ocasiones en que solo se puede acceder a los datos que desea como parte de una página web. En casos como este, querrá usar una técnica llamada web scraping para obtener los datos de la página web en un formato con el que pueda trabajar en su análisis.\n",
    "* Supongamos que encuentra datos de la web y no hay una forma directa de descargarlos. el web scraping con Python es una habilidad que puede usar para extraer los datos en una forma útil facil.\n",
    "* El web scraping es básico para un data science, data engineer o cualquier persona que analice grandes cantidades de conjuntos de datos.\n",
    "\n",
    "## Librerías o Framework de Web Scraping\n",
    "\n",
    "* <b>Requests:</b> Esta librería nos permitirá hacer peticiones HTTP.\n",
    "* <b>BeautifulSoup:</b> Módulo para analizar documentos HTML. Esta biblioteca crea un árbol con todos los elementos del documento y puede ser utilizado para extraer información.\n",
    "* <b>Xpath: </b>Es un Lenguaje que puede navegar y extraer a todas partes dentro de un árbol DOM ('Modelo en Objetos para la Representación de Documentos') HTML.\n",
    "* <b>Selenium:</b> Módulo que se usa para automatizar la interacción con el navegador web desde Python.\n",
    "* <b>Scrapy:</b> Framework de código abierto y colaborativo para extraer los datos que necesita de los sitios web. Es más eficiente que BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerias Necesarias\n",
    "import pandas as pd\n",
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requests\n",
    "La librería requests nos permite enviar solicitudes HTTP con Python.\n",
    "\n",
    "Metodo GET:Cuando queramos obtener o descargar algún archivo html o imagen desde nuestro navegador.\n",
    "\n",
    "Metodo POST:Envia información en forma de formulario, pasamos un diccionario al argumento data.\n",
    "\n",
    "Cuando ejecutamos una solicitud GET o POST el servidor nos devuelve una respuesta (response)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 200 significa que la página se descargó correctamente\n",
    "import requests\n",
    "response=requests.get(\"https://pokemondb.net/pokedex/all\")\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 404  significa que la página no encontrada no existe esa url\n",
    "import requests\n",
    "response=requests.get(\"https://pokemondb.net/pokedex/all\")\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSoup \n",
    "Es una biblioteca de Python para extraer datos de archivos HTML y XML.\n",
    "\n",
    "Si no tienes instalado la distribucion de Ananconda desde la consola cmd\n",
    "```python \n",
    "pip install beautifulsoup4\n",
    "```\n",
    "\n",
    "\n",
    "Ver <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> Manual de  Beautifulsoup4</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc = \"\"\"\n",
    "<html>\n",
    " <head>\n",
    "    <title>Curso de Python</title>\n",
    " </head>\n",
    " <body>\n",
    "  <p class = \"title\"> <b> Introduccion a Python </b> </p>\n",
    "  <p class = \"story\"> Aprenderas \n",
    "    <a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\"> Sintaxis de Python </a>,\n",
    "    <a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\"> WebScraping </a> y\n",
    "    <a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\"> Consumo de Apis Microservicios </a>;\n",
    " y vivían en el fondo de un pozo.\n",
    "  </p>\n",
    " </body>\n",
    "</html>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BeautifulSoup nos da un objeto, que representa el documento como una estructura de datos anidados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# Analizador HTML incluido en la biblioteca estándar de Python, pero también admite varios analizadores Python de terceros\n",
    "# 1 Html.parser de Python No tan rápido como lxml\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "# 2 Analizador HTML de lxml Muy rapido\n",
    "#soup = BeautifulSoup(html_doc, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Curso de Python'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraer titulo del documento HTML\n",
    "soup.title.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Introduccion a Python  '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraer parrafo documento HTML\n",
    "soup.p.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"title\"> <b> Introduccion a Python </b> </p>,\n",
       " <p class=\"story\"> Aprenderas \n",
       "     <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"> Sintaxis de Python </a>,\n",
       "     <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"> WebScraping </a> y\n",
       "     <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\"> Consumo de Apis Microservicios </a>;\n",
       "  y vivían en el fondo de un pozo.\n",
       "   </p>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraer Parrafos del documento HTML\n",
    "soup.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Introduccion a Python  \n",
      " Aprenderas \n",
      "     Sintaxis de Python ,\n",
      "     WebScraping  y\n",
      "     Consumo de Apis Microservicios ;\n",
      " y vivían en el fondo de un pozo.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for p in soup.find_all('p'):\n",
    "    print(p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Introduccion a Python'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quitar espacios\n",
    "soup.p.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"> Sintaxis de Python </a>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraer Enlace del documento HTML\n",
    "soup.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://example.com/elsie'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraer Enlace atributos documento HTML\n",
    "soup.a['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sister']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.a['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'link1'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.a['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "soup.find(name=None, attrs={}, recursive=True, text=None)\n",
    "\n",
    "* <b>name:</b> nombre del elemento html ejemplo: a,p,div,spa,etc.\n",
    "* <b>attrs:</b> atributo del elemento seleccionado ejemplo class,id,etc.\n",
    "* <b>recursive:</b> Si agregamos True puede repetirse o aplicarse indefinidamente la busqueda\n",
    "* <b>text:</b>Busca una palabra o conjunto de palabras en el elemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primera forma\n",
    "elemento3 = soup.find(name=\"a\", attrs={\"id\":\"link3\"}, text=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\"> Consumo de Apis Microservicios </a>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elemento3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segunda forma\n",
    "elemento31 = soup.find(\"a\", id=\"link3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\"> Consumo de Apis Microservicios </a>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elemento31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Laboratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Solucion\n",
    "res = requests.get(\"https://pokemondb.net/pokedex/all\")\n",
    "soup = BeautifulSoup(res.content,'lxml')\n",
    "records = [] \n",
    "table = soup.find_all('table')[0]\n",
    "#print(table)\n",
    "for row in table.findAll(\"tr\"):\n",
    "    cells = row.findAll(\"td\")\n",
    "    numeroOrden=\"\"\n",
    "    nombre=\"\"\n",
    "    tipo=\"\"\n",
    "    for x in cells:\n",
    "        numeroOrden = cells[0].text.strip()\n",
    "        nombre = cells[1].text.strip()\n",
    "        #print(nombre)\n",
    "        tipo = cells[2].text.strip()\n",
    "    #print(nombre)\n",
    "    records.append((numeroOrden,nombre,tipo))\t\n",
    "df = pd.DataFrame(records)\n",
    "df.head(5)\n",
    "df.to_csv('pokemones-2019.csv', sep=';',index=False, encoding='utf-8',header=['N', 'Nombre','Tipo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur Mega Venusaur</td>\n",
       "      <td>Grass Poison</td>\n",
       "      <td>625</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #                    Name          Type  Total  HP  Attack  Defense  \\\n",
       "0  1               Bulbasaur  Grass Poison    318  45      49       49   \n",
       "1  2                 Ivysaur  Grass Poison    405  60      62       63   \n",
       "2  3                Venusaur  Grass Poison    525  80      82       83   \n",
       "3  3  Venusaur Mega Venusaur  Grass Poison    625  80     100      123   \n",
       "4  4              Charmander          Fire    309  39      52       43   \n",
       "\n",
       "   Sp. Atk  Sp. Def  Speed  \n",
       "0       65       65     45  \n",
       "1       80       80     60  \n",
       "2      100      100     80  \n",
       "3      122      120     80  \n",
       "4       60       50     65  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 Solucion\n",
    "import pandas as pd\n",
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get(\"https://pokemondb.net/pokedex/all\")\n",
    "soup = BeautifulSoup(res.content,'lxml')\n",
    "table = soup.find_all('table')[0] \n",
    "df2 = pd.read_html(str(table))[0]\n",
    "df2.head(5)\n",
    "#df.to_csv('pokemones-v2.csv', index=False, encoding='utf-8') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Xpath\n",
    "\n",
    "Es un Lenguaje que puede navegar y extraer a todas partes dentro de un árbol DOM ('Modelo en Objetos para la Representación de Documentos') HTML.\n",
    "\n",
    "La selección del nodo raíz de un documento con XPath es una de las expresiones XPath más cortas: \"/\" (una cadena con solo una barra diagonal).\n",
    "\n",
    "El asterisco aquí, * , significa \"cualquier elemento\". Y /* significa \"cualquier elemento debajo del nodo raíz\". Los documentos HTML tienen solo un elemento como este: el elemento <html> .\n",
    "\n",
    "Otro ejemplo: ¿cómo obtener elementos <title> ? Use /html/head/title :"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
